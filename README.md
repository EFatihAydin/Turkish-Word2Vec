# Turkish Pre-trained Word2Vec Model
(Turkish version is below. / Türkçe için aşağıya bakın.)

This tutorial includes how to train word2vec model for Turkish language from Wikipedia dump. This code is written in Python 3 by using gensim library. Turkish is an agglutinative language and there are many words with the same lemma and different suffixes in the wikipedia corpus. I will write Turkish lemmatizer to increase quality of the model.

#TO-DO#
Tutorial to explain how to create word2vec model 
#TO-DO#

#TO-DO#
Link for Pretrained Model
#TO-DO#

# Eğitilmiş Türkçe Word2Vec Modeli
Bu çalışma Wikipedia'daki Türkçe makalelerden Türkçe word2vec modelinin nasıl çıkarılabileceğini anlatmak için yapılmıştır. Kod gensim kütüphanesi kullanılarak Python 3 ile yazılmıştır. Gelecek zamanlarda, Türkçe "lemmatization" algoritmasıyla aynı kök ve yapım ekleri fakat farklı çekim eklerine sahip kelimelerin aynı kelimeye işaret etmesi sağlanarak modelin kalitesi arttırılacaktır.

#TO-DO#
Tutorial to explain how to create word2vec model 
#TO-DO#

#TO-DO#
Link for Pretrained Model
#TO-DO#
